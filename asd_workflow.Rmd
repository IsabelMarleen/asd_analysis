---
title: 'Workflow: ASD patients versus Controls'
author: "Felix Frauhammer"
date: "10/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages, define functions


```{r libload, message=FALSE, warning=FALSE}
library(DESeq2)
library(BiocParallel)
library( tidyverse )
require( rje )
library( Matrix )
library( irlba )
library( uwot )
library( FNN )
library( igraph )
library( cowplot )
library( RcppAnnoy ) # spotify's library for finding approximate nearest neighbors
```

```{r, echo = FALSE}
# rowVars for sparse matrices:
colVars_spm <- function( spm ) {
  stopifnot( is( spm, "dgCMatrix" ) )
  ans <- sapply( seq.int(spm@Dim[2]), function(j) {
    mean <- sum( spm@x[ (spm@p[j]+1):spm@p[j+1] ] ) / spm@Dim[1]
    sum( ( spm@x[ (spm@p[j]+1):spm@p[j+1] ] - mean )^2 ) +
      mean^2 * ( spm@Dim[1] - ( spm@p[j+1] - spm@p[j] ) ) } ) / ( spm@Dim[1] - 1 )
  names(ans) <- spm@Dimnames[[2]]
  ans
}
rowVars_spm <- function( spm ) {
  colVars_spm( t(spm) )
}


# define scale_color_sqrt (and functions it requires):
power_trans <- function(power){
  # returns transformation object that can be used in ggplot's scale_*_continuous
  scales::trans_new(
    name = "tmp",
    trans = function(x)   x^(power),
    inverse = function(x) x^(1/power),
    breaks = function(lims, p) power_breaks(lims, p=power) )
}
power_breaks <- function(lims, power, n_breaks=5){
  # Return vector of breaks that span the lims range evenly _after_ power transformation:
  lims[1] <- max(0, lims[1]) # non-integer exponents are not defined for negative values
  x <- seq(lims[1]^power, lims[2]^(power), length.out = n_breaks)^(1/power)
  # make human-readable by rounding to the closest integer power of 2. Smallest
  # and largest ticks are not strictly rounded - instead they are moved within
  # the range of values, since ggplot would not display them otherwise:
  x <- case_when(
    x == max(x) ~ 2^(floor(log2(x))),
    x == min(x) ~ 2^(ceiling(log2(x))),
    TRUE ~ (2^(round(log2(x)))) 
  )
  return(x)
}
semi_scientific_formatting <- function(x) {
  # takes numeric vector x and returns character vector where extremely large / small
  # numbers are in scientific notation (e.g. 1e-30) while others are untouched:
  x <- case_when(
    x == 0 ~ as.character(0),
    abs(x) < .01 | abs(x) >= 1000 ~ scales::scientific(x,  digits = 0),
    TRUE ~ as.character(x))}
scale_color_sqrt <- function(...){scale_color_gradientn(
                        colours = rev(rje::cubeHelix(100))[5:100],
                        trans = power_trans(1/2),
                        labels = semi_scientific_formatting,
                        ...)}
```

## Load data

The matrix with raw UMI counts can be downloaded from [here](http://cells.ucsc.edu/?ds=autism#). This section reads them
into R.

```{r}
path <- "~/sds/sd17l002/p/ASD/"

counts <- readMM( file.path( path, "rawMatrix", "matrix.mtx" ) )
# make gene symbols unique (by concatenating ensembleID where necessary):
gene_info <- read.delim( file.path( path, "rawMatrix", "genes.tsv" ), header=FALSE, as.is=TRUE ) %>%
  mutate(unique = case_when(
  duplicated(V2) | duplicated(V2, fromLast=T) ~ paste(V2, V1, sep="_"),
  TRUE ~ V2))
rownames(counts) <- gene_info$unique
colnames(counts) <- readLines( file.path( path, "rawMatrix", "barcodes.tsv" ) )

# info per cell:
cellinfo <- read.delim( file.path( path, "rawMatrix", "meta.txt" ), stringsAsFactors=FALSE )
# info per patient:
sampleTable <-
  cellinfo %>% select( sample : RNA.Integrity.Number ) %>% unique
sampleTable
```


Some operations are faster in column-sparse format than in tripel-sparse.
We recommend pre-computing these two matrices if time is more important
than RAM for you:
```{r tcounts}
Tcounts <- as(t(counts), "dgCMatrix") #  fast: Tcounts[, "SYN1"]
Ccounts <- as(counts, "dgCMatrix")    #  fast: Ccounts[, 1337] & colSums(Ccounts)
```



## PCA and UMAP

We start with simple size-factor normalization:
```{r}
sfs <- colSums(Ccounts)
norm_counts <- t(t(Ccounts) / sfs)
rownames(norm_counts) <- rownames(Ccounts)
```

UMI-based gene expression data has Poisson noise (see for example [the GLM-PCA preprint](https://www.biorxiv.org/content/10.1101/574574v1)). We are only 
interested in genes that show variation above the expected Poisson variance
(`is_informative`) and came up with a very simple strategy to find them 
(we are planning to write up the theoretical details at some point): 
```{r}
poisson_vmr <- mean(1/sfs)
gene_means <- rowMeans( norm_counts )
gene_vars <- rowVars_spm( norm_counts )
is_expressed <- colSums( Tcounts != 0 ) > 100
is_informative <- gene_vars/gene_means > 1.5 * poisson_vmr  &  is_expressed
plot(gene_means, gene_vars/gene_means, pch=".", log = "xy")
points(gene_means[is_informative], (gene_vars/gene_means)[is_informative], pch=".", col = "red" )
```



```{r pca}
pca <- irlba::prcomp_irlba( x = sqrt(t(norm_counts[is_informative,])),
                            n = 40,
                            scale. = TRUE)
umap_euc <- uwot::umap( pca$x, spread = 10, n_threads = 40) # euc: euclidean distance
```




## Find celltypes with clustering

Clustering scRNAseq data starts with finding each cell's nearest neighbors in PCA space.
For this we use the
[RcppAnnoy package](https://github.com/eddelbuettel/rcppannoy), 
originally developed by Spotify to find music recommendations. It works just as
well for single-cell data and is faster than 
[FNN](https://cran.r-project.org/web/packages/FNN/index.html),
but the code is a bit bulky:
```{r louvain_findNN}
# find NN for each cell:
featureMatrix <- pca$x; k_nn <- 50
annoy <- new( AnnoyEuclidean, ncol(featureMatrix) )
for( i in 1:nrow(featureMatrix) ) 
  annoy$addItem( i-1, featureMatrix[i,] )
annoy$build( 50 ) # builds a forest  of n_trees trees. More trees gives higher precision when querying.
nn_cells <- t( sapply( 1:annoy$getNItems(), function(i) annoy$getNNsByItem( i-1, k_nn) + 1 ) )
nndists_cells <- sapply( 1:ncol(nn_cells), function(j) sqrt( rowSums( ( featureMatrix - featureMatrix[ nn_cells[,j], ] )^2 ) ) )
rm(featureMatrix, annoy)
```

We now find clusters with Louvain clustering:
```{r louvain_graph}
# has to be sparse, otherwise takes 80 GB of RAM:
adj <- Matrix(0, nrow = nrow(pca$x), ncol = nrow(pca$x)) 
for(i in 1:ncol(nn_cells))
  adj[ cbind(1:nrow(pca$x), nn_cells[, i]) ] <- 1
for(i in 1:ncol(nn_cells))
  adj[ cbind(nn_cells[, i], 1:nrow(pca$x)) ] <- 1
cl_louvain <- cluster_louvain(  graph_from_adjacency_matrix(adj, mode = "undirected") )
```

To each cluster, we assign a celltype. This is based on gene expression plots
not shown here, and we merge clusters whose separation is not convincing us.
```{r louvain_merge}
celltypes_louv <- cl_louvain$membership
celltypes_louv <- case_when(
  # assign celltypes to clusters:
  celltypes_louv == 4  ~ "Oligodendrocyte",
  celltypes_louv == 5  ~ "IN_PV",
  celltypes_louv == 11 ~ "IN_SV2C",
  celltypes_louv == 13 ~ "Microglia",
  celltypes_louv == 14 ~ "IN_VIP",
  celltypes_louv == 20 ~ "neurons_NRGN",
  celltypes_louv == 12 ~ "IN_SST",
  # clusters we merge:
  celltypes_louv %in% c(1, 7, 17, 24, 19, 6, 18, 16) ~ "Neuron_excit",
  celltypes_louv %in% c(2, 21, 15) ~ "Astrocyte",
  celltypes_louv %in% c(3, 9, 10) ~ "OPC",
  celltypes_louv %in% c(23) ~ "Endo_and_pericyte",
  TRUE ~ "unassigned") %>% factor()
```


```{r louvain_plots, echo=FALSE}
# Louvain clusters 
p_louv <- ggplot()+ coord_fixed() + theme(legend.position = "none") +
  geom_point(data = data.frame(umap_euc, cl=celltypes_louv),
             aes(X1, X2, col = cl), size = .1) +
  geom_label(data = data.frame(umap_euc, cl=celltypes_louv) %>%
               group_by(cl) %>% summarise(X1=mean(X1), X2=mean(X2)), 
             aes(X1, X2, label = cl))

# clusters from paper
p_paper <- ggplot()+ coord_fixed()+theme(legend.position = "none") +
  geom_point(data =data.frame(cell = colnames(counts), umap_euc) %>%
               left_join(select(cellinfo, cell, cluster), by="cell"),
             aes(X1, X2, col = cluster), size = .1) +
  geom_label(data = data.frame(cell = colnames(counts), umap_euc) %>%
               left_join(select(cellinfo, cell, cluster), by = "cell") %>% 
               group_by(cluster) %>%
               summarise(X1=mean(X1), X2=mean(X2)),
             aes(X1, X2, label = cluster))

plot_grid(
  p_louv + ggtitle("Louvain clusters"),
  p_paper+ ggtitle("Clusters from Velmeshev et al., Science 2019")
)
```


## Doublets and ambiguous cells



```{r}
# number of NN from different cluster:
nn_inothercluster <- colSums(
  matrix(celltypes_louv[ t(nn_cells) ],
         ncol = nrow(nn_cells))   != 
  matrix(rep(celltypes_louv, each = ncol(nn_cells)),
         ncol = nrow(nn_cells)) )
```

We simulate doublets *in silico* by the simplest way possible: we randomly
draw cells from different clusters and pool their UMIs. For each
cell in our experiment, we ask how many of such **synthetic doublets** it has
amongst its nearest neighbors and save this values in `dblts_perc` - we will
use this further below to exclude putative doublet cells from further analysis.
Credit for this approach goes to published doublet detection tools such as
[DoubletFinder](https://www.sciencedirect.com/science/article/abs/pii/S2405471219300730)
and
[Scrublet](https://www.sciencedirect.com/science/article/abs/pii/S2405471218304745).
```{r doublet_drawCells}
# for each sample, we draw random pairs of cells (their ids go to columns of a matrix):
doublet_ids <- sapply(unique(cellinfo$sample), function(smp) {
  is_smp <- cellinfo$sample == smp
  matrix(sample(x = which(is_smp),
                size = 2*floor(sum(is_smp)/2)),  # 2*floor(x/2) makes x even
         ncol = 2)
}) %>% do.call(rbind, .)

doublet_raw <- Ccounts[, doublet_ids[,1]] + Ccounts[, doublet_ids[,2]]
doublet_pcs <- predict(pca,
                       newdata = sqrt( (t(doublet_raw) / colSums(doublet_raw))[, is_informative] ))

```

We again use RcppAnnoy to find nearest neighbors, this time also for the 
synthetic doublets on top of the cells:
```{r}
featureMatrix <- rbind(pca$x, doublet_pcs); k_nn <- 50
annoy <- new( AnnoyEuclidean, ncol(featureMatrix) )
for( i in 1:nrow(featureMatrix) ) 
  annoy$addItem( i-1, featureMatrix[i,] )
annoy$build( 50 ) # builds a forest  of n_trees trees. More trees gives higher precision when querying.
nn_doublets <- t( sapply( 1:annoy$getNItems(), function(i) annoy$getNNsByItem( i-1, k_nn) + 1 ) )
nndists_doublets <- sapply( 1:ncol(nn_doublets), function(j) sqrt( rowSums( ( featureMatrix - featureMatrix[ nn_doublets[,j], ] )^2 ) ) )
rm(featureMatrix, annoy)


# percentage of synthetic doublets in neighborhood for each cell:
dblts_perc <- rowMeans( nn_doublets > ncol(counts) )[ 1:ncol(counts) ]



# Run UMAP with Annoy's output
ump2 <- uwot::umap( NULL, nn_method = list( idx=nn_doublets, dist=nndists_doublets), 
                    n_threads=40, spread = 15, verbose=TRUE )

is_synth <- 1:nrow(ump2) > nrow(pca$x)
```



```{r, echo=FALSE}
tmp <- data.frame(umap_euc,
                  diagnosis = cellinfo$diagnosis,
                  clean = dblts_perc < 3/50  & nn_inothercluster < 1,
                  Gene = Tcounts[, "TTF2"] / sfs/mean(1/sfs),
                  cl = celltypes_louv)
ggplot() + coord_fixed()+
  geom_point(data=filter(tmp,  clean), aes(X1, X2, col = cl), size=.1) +
  geom_point(data=filter(tmp, !clean), aes(X1, X2), col = "black", size=.1) +
  geom_label(data=group_by(tmp, cl) %>% summarise(X1=mean(X1), X2=mean(X2)), aes(X1, X2, label=cl)) + ggtitle("Black dots show cells with doublets/wrong cluster amongst NN")

tmp <- as.matrix(table(sample=cellinfo$sample, clean = dblts_perc < 3/50  & nn_inothercluster < 1))
data.frame(sample = rownames(tmp), dirtyProportion = tmp[,1] / (tmp[,1] + tmp[,2])) %>% left_join(sampleTable, by="sample") %>% ggplot(aes(sample, dirtyProportion, col = diagnosis))+geom_point() + ylab("% of cells with doublets/wrong cluster amongst NN")

```






## Find celltypes with smoothing

```{r}
tricube_fromNN1 <- function(x, halfwidth=1) {
  # tricube kernel function with sef: self equals first neighbor.
  #
  # formula adapted from (wikipedia)[https://en.wikipedia.org/wiki/Kernel_(statistics)],
  # and expanded to contain `halfwidth`.
  # distance to oneself is 0 so we mask it:
  self_id <- which.min(x)
  x[self_id] <- NA
  nn_dist <- min(x, na.rm = TRUE) # distance to first nearest neighbor
  x <- x - nn_dist
  halfwidth <- halfwidth - nn_dist
  tricube <- 70/81/halfwidth * (1 - abs(x/halfwidth)^3)^3
  # outside of kernel support (-halfwidth, +halfwidth), tricube is defined as 0:
  tricube[ abs(x) > halfwidth ] <- 0
  tricube[self_id] <- tricube[which.max(tricube)]
  return(tricube)
}


kernel_weights <- apply(nndists_cells,
                        1,
                        function(d) tricube_fromNN1(d, max(d)))
```


```{r}
knn_smooth <- function(g = "SYT1"){
# knn-smooth a gene with tricube weights
 norm_umis <- matrix(Ccounts[g, c(nn_cells)] / sfs[c(nn_cells)],
                     ncol = ncol(nn_cells))
 knn_smoothed <- rowSums(norm_umis * t(kernel_weights)) / colSums(kernel_weights)
}


make_p <- function(df) {  # custom function to save some typing - pure laziness
  ggplot(data=df, aes(X1, X2, col = Gene))+geom_point(size=.1)+coord_fixed() +
  scale_color_gradientn(colours = rev(rje::cubeHelix(100))[5:100], trans = "sqrt")
}
```




```{r}
syt1 <- knn_smooth("SYT1")
cux2 <- knn_smooth("CUX2")
DPP10<- knn_smooth("DPP10") # anticorrelated with CUX2, 
rorb <- knn_smooth("RORB")
```

Smoothing looks convincing:
```{r}
plot_grid(
    data.frame(umap_euc, Gene = Tcounts[, "SYT1"]/sfs) %>% make_p,
    data.frame(umap_euc, Gene = syt1) %>% make_p
)
```




### CUX2 cells


Cells can be separated in principle by smoothed cux2 expression:
```{r}
data.frame(umap_euc, syt1, cux2, rorb) %>% 
  ggplot() + geom_point(aes(syt1, cux2, col = cux2 > .00025), size=.1) + coord_fixed() + 
  scale_x_continuous(trans = "sqrt") +
  scale_y_continuous(trans = "sqrt")
```
Patient heterogeneity in CUX2:
```{r}
data.frame(cellinfo, cux2, celltypes_louv) %>%
  mutate(tmp = case_when(
    celltypes_louv %in% c("Neuron_excit", "neurons_NRGN") ~ as.character(celltypes_louv),
    TRUE ~ "other"
  ) ) %>% 
  ggplot(aes(factor(sample), cux2, col = tmp))+geom_jitter(size=.1) + 
  scale_y_continuous(trans=power_trans(1/2)) +
  theme(axis.text.x  =  element_text(angle = 90))




data.frame(cellinfo, cux2, celltypes_louv) %>%
  mutate(tmp = case_when(
    celltypes_louv %in% c("Neuron_excit", "neurons_NRGN") ~ as.character(celltypes_louv),
    TRUE ~ "other"
  ) ) %>% 
  filter(celltypes_louv == "Neuron_excit") %>%
  ggplot(aes(cux2, col = factor(sample)))+geom_density()
  scale_x_continuous(trans=power_trans(1/2)) +
  theme(axis.text.x  =  element_text(angle = 90))
```



What correlates with cux2? 
```{r}
sel <- celltypes_louv == "Neuron_excit"   &   
  dblts_perc < 3/50  & nn_inothercluster < 1
poisson_vmr <- mean(1/sfs[sel])
gene_means <- rowMeans( norm_counts[, sel] )
gene_vars <- rowVars_spm( norm_counts[,sel] )
is_expressed <- colSums( Tcounts[sel,] != 0 ) > 200
is_informative <- gene_vars/gene_means > 1.5 * poisson_vmr  &  is_expressed
plot(gene_means, gene_vars/gene_means, pch=".", log = "xy")
points(gene_means[is_informative], (gene_vars/gene_means)[is_informative], pch=".", col = "red" )

# compute patient-ignorant (across all cells)
gene_cors <- cor(cux2[sel], as.matrix(t(norm_counts[is_informative,sel])))
gene_cors <- gene_cors[1,] # from matrix to vector
head(sort(abs(gene_cors), decreasing = T), n=20)
```

```{r}
plot_grid(
  data.frame(umap_euc, Gene = Tcounts[, "CUX2"]/sfs) %>% make_p,
  data.frame(umap_euc, Gene = Tcounts[, "DPP10"]/sfs) %>% make_p
)
```

ASD vs control: do gene correlations with CUX2 change with disease?
```{r}
normcounts_for_cor <- as.matrix(t(norm_counts[is_informative, ]))
cux2_for_cor <- norm_counts["CUX2", ]
cors_per_sample <- lapply(unique(cellinfo$sample), function(smp){
  smp_sel <- cellinfo$sample == smp  &  sel
  print(paste0(smp, ":  ", sum(smp_sel)))
  drop(cor(cux2_for_cor[smp_sel], normcounts_for_cor[smp_sel,]))
}) %>% do.call(cbind, .)
colnames(cors_per_sample) <- unique(cellinfo$sample)

cors_factor <- data.frame(sample = colnames(cors_per_sample), stringsAsFactors = F) %>%
  left_join(sampleTable, by = "sample") %>% pull(diagnosis) %>% factor

library(genefilter)
res <- rowttests(cors_per_sample, cors_factor, tstatOnly = FALSE) 
res %>% rownames_to_column("Gene") %>% filter(p.value < .1) %>% arrange(desc(dm)) %>% head(n=20)
```


```{r}
data.frame(cors_factor,t(cors_per_sample)) %>%
  ggplot(aes(cors_factor, PBX1))+geom_point()
```




### Excitatory Neurons, Oligodendrocytes, ...
Celltypes:
```{r}
plot_grid(
  p_louv + ggtitle("Louvain clusters"),
  p_paper+ ggtitle("Clusters from Velmeshev et al., Science 2019")
)
```


Excitatory Neurons
```{r}
SLC17A7 <- knn_smooth("SLC17A7") # glial cells + endo
data.frame(umap_euc, Gene = Tcounts[, "SLC17A7"]/sfs) %>% make_p
data.frame(umap_euc, Gene = SLC17A7) %>% make_p
```



Oligodendrocytes
```{r}
PLP1 <- knn_smooth("PLP1")
data.frame(umap_euc, Gene = Tcounts[, "PLP1"]/sfs) %>% make_p
data.frame(umap_euc, Gene = PLP1) %>% make_p
```



Glial cells + endo according to paper, but I think it's astrocytes only
(in Science paper, microglia are marked nicely... could that be overplotting?!)
```{r}
SLC1A2 <- knn_smooth("SLC1A2")

data.frame(umap_euc, Gene = Tcounts[, "SLC1A2"]/sfs) %>% make_p
data.frame(umap_euc, Gene = SLC1A2/mean(1/sfs)) %>% make_p
```




Layer 2/3 (Margot and Simon)
```{r}
data.frame(umap_euc, Gene = Tcounts[, "CARM1P1"]/sfs) %>% make_p
```





## Compare Autism versus Control


```{r}
sel <- celltypes_louv == "Neuron_excit"  & dblts_perc < 3/50  & nn_inothercluster < 1
pseudobulks <- as.matrix(t( fac2sparse(cellinfo$sample[sel]) %*% t(Ccounts[, sel]) ))
coldat <- filter(sampleTable, sample %in% colnames(pseudobulks)) %>% 
  mutate(individual = factor(individual),
         diagnosis = factor(diagnosis, levels = c("Control", "ASD")),
         region    = factor(region))
rownames(coldat) <- coldat$sample

dds <- DESeq2::DESeqDataSetFromMatrix( pseudobulks,
                               coldat[colnames(pseudobulks), ],
                               design = ~ sex + region + age + diagnosis )
# For cluster 5, I tested that we do not need interactions between sex, region and diagnosis. I used
# DESeq's LTR for this (see mail to Simon at mid-September 2019).
dds <- DESeq2::DESeq(dds, 
             parallel=TRUE, BPPARAM=BiocParallel::MulticoreParam(20))
res_df <- DESeq2::results(dds, name = "diagnosis_ASD_vs_Control") %>% as.data.frame() %>% rownames_to_column("Gene")



data.frame(umap_euc, Gene = Tcounts[, "ZNF770"], sfs=sfs, diagnosis=cellinfo$diagnosis) %>%
  ggplot(aes(X1, X2, col=Gene/sfs/mean(1/sfs)))+geom_point(size=.1) +
  scale_color_sqrt(name="ZNF770") +
  facet_wrap(~ diagnosis) + coord_fixed()

```








## savepoint

```{r}
# save(pca,
#      file = file.path(path, "savepoint", "pca_40pcs_scaling_2311genes.RData"))
# save(umap_euc,
#      file = file.path(path, "savepoint", "umap_euc_spread10.RData"))
# 
# 
# save(list = c("cl_louvain", "celltypes_louv", "nn_cells", "nndists_cells",
#               "nn_inothercluster"),
#      file = file.path(path, "savepoint", "clusters.RData"))
# 
# save(list = c("nn_doublets", "nndists_doublets", "cellsA", "cellsB",
#                 "dblts_perc", "is_synth", "ump2"),
#      file = file.path(path, "savepoint", "doublets.RData"))


load(file.path(path, "savepoint", "pca_40pcs_scaling_2311genes.RData"))
load(file.path(path, "savepoint", "umap_euc_spread10.RData"))
load(file.path(path, "savepoint", "clusters.RData"))
load(file.path(path, "savepoint", "doublets.RData"))
```













## Linked charts

HVGs for excitatory Neurons:
```{r hvg_excit}
is_cl  <- celltypes_louv == "Neuron_excit"   &   
  dblts_perc < 3/50  & nn_inothercluster < 1
# 

# counts <- counts[, is_cl]  # to make it fit into laptop memory
counts <- as(counts, "dgCMatrix")
sfs <- colSums(counts)
norm_counts <- t(t(counts[, is_cl]) / sfs[is_cl])
rownames(norm_counts) <- rownames(counts)

poisson_vmr <- mean(1/sfs[is_cl])
gene_means <- rowMeans( norm_counts )
gene_vars <- rowVars_spm( norm_counts )
is_expressed <- rowSums( norm_counts != 0 ) > 100
is_informative <- gene_vars/gene_means > 1.5 * poisson_vmr  &  is_expressed
plot(gene_means, gene_vars/gene_means, pch=".", log = "xy")
points(gene_means[is_informative], (gene_vars/gene_means)[is_informative], pch=".", col = "red" )
```


```{r rlc}
library(rlc)


nn_cells_cl <- nn_cells[is_cl, ]
kernel_weights <- apply(nndists_cells[is_cl, ],
                        1,
                        function(d) tricube_fromNN1(d, max(d)))


# knn-smooth a gene with tricube weights
g <- "CUX2"
norm_umis <- matrix(counts[g, c(nn_cells_cl)] / sfs[c(nn_cells_cl)],
                    ncol = ncol(nn_cells_cl))
knn_smoothed <- rowSums(norm_umis * t(kernel_weights)) /
                colSums(kernel_weights)





data.frame(cell=colnames(counts), umap_euc) %>% left_join(data.frame(cell = colnames(counts)[is_cl], Gene = knn_smoothed)) %>% ggplot(aes(X1, X2, col = Gene))+geom_point(size=.1) + scale_color_sqrt()
```

linked chart:
```{r}
inverse_gamma <- 1
means <- log10(gene_means[is_expressed])
vars  <- log10( (gene_vars/gene_means)[is_expressed] )
genes <- names(means)

smooth_list <- lapply(genes, function(x) NULL)
names(smooth_list) <- genes

knn_smooth <- function(g){
  if(is.null(smooth_list[[g]])){
   norm_umis <- matrix(counts[g, c(nn_cells_cl)] / sfs[c(nn_cells_cl)],
                      ncol = ncol(nn_cells_cl))
   knn_smoothed <- rowSums(norm_umis * t(kernel_weights)) /
                   colSums(kernel_weights)   
   smooth_list[[g]] <<- knn_smoothed}
  return(smooth_list[[g]])
}
gene <- "CUX2"

openPage()
lc_scatter(dat(size = 2,
               title = gene,
               on_click = function(value) {
                 gene <<- genes[value]
                 updateCharts(c("vmr", "A1"),
                              updateOnly = c("Title", ""))
               }),
           x = means,
           y = vars,
           width = 400, height = 400,
           "vmr"
)

lc_hist(dat(value = knn_smooth(gene)^(1/inverse_gamma),
            title = gene,
            nbins = 30), "A1")


lc_input(type = "range",
         label = c("Inverse Power (1/gamma)"),
         width = 300,
         value = c(1),
         min = c(1),
         max = c(10),
         step = c(1),
         on_change = function(value) {
           inverse_gamma <<- value[1]
           updateCharts("A1")

         })


```

Manually I click through some genes and note down bimodal ones here:
```{r}
bimodal_genes <- c(
  "KIAA1217",
  "HTR2C",
  "ZNF385D",
  "TSHZ2",
  "HS3ST4",  # trimodal?
  "DLC1",
  "POU6F2",  # ill-separated peaks
  "CA10",  # ill-separated peaks
  "TMTC2",  # ill-separated peaks
  "CACNB2",  # ill-separated peaks
  "CTC-535M15.2",
  "Meis2",  # VMR is not spectacular but bimodality well visible
  "GRIN1",
  "CNTNAP5",
  "CPNE4"
  
)

not_bimodal <- c(
  "GPC5",
  "ENC1",
  "PTPRT",
  "SYN2",
  "STMN1",
  "INO80D",
  "MCTP1"  # trimodal, in my opinion
  
)
```








