---
title: 'Workflow: ASD patients versus Controls'
author: "Felix Frauhammer"
date: "10/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages, define functions


```{r libload, message=FALSE, warning=FALSE}
library(DESeq2)
library(BiocParallel)
library( tidyverse )
require( rje )
library( Matrix )
library( irlba )
library( uwot )
library( FNN )
library( igraph )
library( cowplot )
library( RcppAnnoy ) # spotify's library for finding approximate nearest neighbors
```

```{r, echo = FALSE}
# rowVars for sparse matrices:
colVars_spm <- function( spm ) {
  stopifnot( is( spm, "dgCMatrix" ) )
  ans <- sapply( seq.int(spm@Dim[2]), function(j) {
    mean <- sum( spm@x[ (spm@p[j]+1):spm@p[j+1] ] ) / spm@Dim[1]
    sum( ( spm@x[ (spm@p[j]+1):spm@p[j+1] ] - mean )^2 ) +
      mean^2 * ( spm@Dim[1] - ( spm@p[j+1] - spm@p[j] ) ) } ) / ( spm@Dim[1] - 1 )
  names(ans) <- spm@Dimnames[[2]]
  ans
}
rowVars_spm <- function( spm ) {
  colVars_spm( t(spm) )
}


# define scale_color_sqrt (and functions it requires):
power_trans <- function(power){
  # returns transformation object that can be used in ggplot's scale_*_continuous
  scales::trans_new(
    name = "tmp",
    trans = function(x)   x^(power),
    inverse = function(x) x^(1/power),
    breaks = function(lims, p) power_breaks(lims, p=power) )
}
power_breaks <- function(lims, power, n_breaks=5){
  # Return vector of breaks that span the lims range evenly _after_ power transformation:
  lims[1] <- max(0, lims[1]) # non-integer exponents are not defined for negative values
  x <- seq(lims[1]^power, lims[2]^(power), length.out = n_breaks)^(1/power)
  # make human-readable by rounding to the closest integer power of 2. Smallest
  # and largest ticks are not strictly rounded - instead they are moved within
  # the range of values, since ggplot would not display them otherwise:
  x <- case_when(
    x == max(x) ~ 2^(floor(log2(x))),
    x == min(x) ~ 2^(ceiling(log2(x))),
    TRUE ~ (2^(round(log2(x)))) 
  )
  return(x)
}
semi_scientific_formatting <- function(x) {
  # takes numeric vector x and returns character vector where extremely large / small
  # numbers are in scientific notation (e.g. 1e-30) while others are untouched:
  x <- case_when(
    x == 0 ~ as.character(0),
    abs(x) < .01 | abs(x) >= 1000 ~ scales::scientific(x,  digits = 0),
    TRUE ~ as.character(x))}
scale_color_sqrt <- function(...){scale_color_gradientn(
                        colours = rev(rje::cubeHelix(100))[5:100],
                        trans = power_trans(1/2),
                        labels = semi_scientific_formatting,
                        ...)}
```

## Load data

The matrix with raw UMI counts can be downloaded from [here](http://cells.ucsc.edu/?ds=autism#). This section reads them
into R.

```{r}
path <- "~/sds/sd17l002/p/ASD/"


counts <- readMM( file.path( path, "rawMatrix", "matrix.mtx" ) )
# make gene symbols unique (by concatenating ensembleID where necessary):
gene_info <- read.delim( file.path( path, "rawMatrix", "genes.tsv" ), header=FALSE, as.is=TRUE ) %>%
  mutate(unique = case_when(
  duplicated(V2) | duplicated(V2, fromLast=T) ~ paste(V2, V1, sep="_"),
  TRUE ~ V2))
rownames(counts) <- gene_info$unique
colnames(counts) <- readLines( file.path( path, "rawMatrix", "barcodes.tsv" ) )

# info per cell (append tSNE we downloaded from cells.ucsc.edu as well):
cellinfo <- read.delim( file.path( path, "rawMatrix", "meta.txt" ), stringsAsFactors=FALSE ) %>%
  left_join(read_tsv(file.path(path, "rawMatrix", "tSNE.coords.tsv"),
                     col_names = c("cell", "tSNE1", "tSNE2")),
            by = "cell") %>% select(cell, tSNE1, tSNE2, everything())
# info per patient:
sampleTable <-
  cellinfo %>% select( sample : RNA.Integrity.Number ) %>% unique
sampleTable
```


Some operations are faster in column-sparse format than in tripel-sparse.
We recommend pre-computing these two matrices if time is more important
than RAM for you:
```{r tcounts}
Tcounts <- as(t(counts), "dgCMatrix") #  fast: Tcounts[, "SYN1"]
Ccounts <- as(counts, "dgCMatrix")    #  fast: Ccounts[, 1337] & colSums(Ccounts)
```



## PCA and UMAP

We start with simple size-factor normalization:
```{r}
sfs <- colSums(Ccounts)
norm_counts <- t(t(Ccounts) / sfs)
rownames(norm_counts) <- rownames(Ccounts)
```

UMI-based gene expression data has Poisson noise (see for example [the GLM-PCA preprint](https://www.biorxiv.org/content/10.1101/574574v1)). We are only 
interested in genes that show variation above the expected Poisson variance
(`is_informative`) and came up with a very simple strategy to find them 
(we are planning to write up the theoretical details at some point): 
```{r}
poisson_vmr <- mean(1/sfs)
gene_means <- rowMeans( norm_counts )
gene_vars <- rowVars_spm( norm_counts )
is_expressed <- colSums( Tcounts != 0 ) > 100
is_informative <- gene_vars/gene_means > 1.5 * poisson_vmr  &  is_expressed
plot(gene_means, gene_vars/gene_means, pch=".", log = "xy")
points(gene_means[is_informative], (gene_vars/gene_means)[is_informative], pch=".", col = "red" )
```



```{r pca}
pca <- irlba::prcomp_irlba( x = sqrt(t(norm_counts[is_informative,])),
                            n = 40,
                            scale. = TRUE)
umap_euc <- uwot::umap( pca$x, spread = 10, n_threads = 40) # euc: euclidean distance
```




## Find celltypes with clustering

Clustering scRNAseq data starts with finding each cell's nearest neighbors in PCA space.
For this we use the
[RcppAnnoy package](https://github.com/eddelbuettel/rcppannoy), 
originally developed by Spotify to find music recommendations. It works just as
well for single-cell data and is faster than 
[FNN](https://cran.r-project.org/web/packages/FNN/index.html),
but the code is a bit bulky:
```{r louvain_findNN}
# find NN for each cell:
featureMatrix <- pca$x; k_nn <- 50
annoy <- new( AnnoyEuclidean, ncol(featureMatrix) )
for( i in 1:nrow(featureMatrix) ) 
  annoy$addItem( i-1, featureMatrix[i,] )
annoy$build( 50 ) # builds a forest  of n_trees trees. More trees gives higher precision when querying.
nn_cells <- t( sapply( 1:annoy$getNItems(), function(i) annoy$getNNsByItem( i-1, k_nn) + 1 ) )
nndists_cells <- sapply( 1:ncol(nn_cells), function(j) sqrt( rowSums( ( featureMatrix - featureMatrix[ nn_cells[,j], ] )^2 ) ) )
rm(featureMatrix, annoy)
```

We now find clusters with Louvain clustering:
```{r louvain_graph}
# has to be sparse, otherwise takes 80 GB of RAM:
adj <- Matrix(0, nrow = nrow(pca$x), ncol = nrow(pca$x)) 
for(i in 1:ncol(nn_cells))
  adj[ cbind(1:nrow(pca$x), nn_cells[, i]) ] <- 1
for(i in 1:ncol(nn_cells))
  adj[ cbind(nn_cells[, i], 1:nrow(pca$x)) ] <- 1
cl_louvain <- cluster_louvain(  graph_from_adjacency_matrix(adj, mode = "undirected") )
```

To each cluster, we assign a celltype. This is based on gene expression plots
not shown here, and we merge clusters whose separation is not convincing us.
```{r louvain_merge}
celltypes_louv <- cl_louvain$membership
celltypes_louv <- case_when(
  # assign celltypes to clusters:
  celltypes_louv == 4  ~ "Oligodendrocyte",
  celltypes_louv == 5  ~ "IN_PV",
  celltypes_louv == 11 ~ "IN_SV2C",
  celltypes_louv == 13 ~ "Microglia",
  celltypes_louv == 14 ~ "IN_VIP",
  celltypes_louv == 20 ~ "neurons_NRGN",
  celltypes_louv == 12 ~ "IN_SST",
  # clusters we merge:
  celltypes_louv %in% c(1, 7, 17, 24, 19, 6, 18, 16) ~ "Neuron_excit",
  celltypes_louv %in% c(2, 21, 15) ~ "Astrocyte",
  celltypes_louv %in% c(3, 9, 10) ~ "OPC",
  celltypes_louv %in% c(23) ~ "Endo_and_pericyte",
  TRUE ~ "unassigned") %>% factor()
```


```{r louvain_plots, echo=FALSE}
# Louvain clusters 
p_louv <- ggplot()+ coord_fixed() + theme(legend.position = "none") +
  geom_point(data = data.frame(umap_euc, cl=celltypes_louv),
             aes(X1, X2, col = cl), size = .1) +
  geom_label(data = data.frame(umap_euc, cl=celltypes_louv) %>%
               group_by(cl) %>% summarise(X1=mean(X1), X2=mean(X2)), 
             aes(X1, X2, label = cl))

# clusters from paper
p_paper <- ggplot()+ coord_fixed()+theme(legend.position = "none") +
  geom_point(data =data.frame(cell = colnames(counts), umap_euc) %>%
               left_join(select(cellinfo, cell, cluster), by="cell"),
             aes(X1, X2, col = cluster), size = .1) +
  geom_label(data = data.frame(cell = colnames(counts), umap_euc) %>%
               left_join(select(cellinfo, cell, cluster), by = "cell") %>% 
               group_by(cluster) %>%
               summarise(X1=mean(X1), X2=mean(X2)),
             aes(X1, X2, label = cluster))

plot_grid(
  p_louv + ggtitle("Louvain clusters"),
  p_paper+ ggtitle("Clusters from Velmeshev et al., Science 2019")
)
```


## Doublets and ambiguous cells



```{r}
# number of NN from different cluster:
nn_inothercluster <- colSums(
  matrix(celltypes_louv[ t(nn_cells) ],
         ncol = nrow(nn_cells))   != 
  matrix(rep(celltypes_louv, each = ncol(nn_cells)),
         ncol = nrow(nn_cells)) )
```

We simulate doublets *in silico* by the simplest way possible: we randomly
draw cells from different clusters and pool their UMIs. For each
cell in our experiment, we ask how many of such **synthetic doublets** it has
amongst its nearest neighbors and save this values in `dblts_perc` - we will
use this further below to exclude putative doublet cells from further analysis.
Credit for this approach goes to published doublet detection tools such as
[DoubletFinder](https://www.sciencedirect.com/science/article/abs/pii/S2405471219300730)
and
[Scrublet](https://www.sciencedirect.com/science/article/abs/pii/S2405471218304745).
```{r doublet_drawCells}
# for each sample, we draw random pairs of cells (their ids go to columns of a matrix):
doublet_ids <- sapply(unique(cellinfo$sample), function(smp) {
  is_smp <- cellinfo$sample == smp
  matrix(sample(x = which(is_smp),
                size = 2*floor(sum(is_smp)/2)),  # 2*floor(x/2) makes x even
         ncol = 2)
}) %>% do.call(rbind, .)

doublet_raw <- Ccounts[, doublet_ids[,1]] + Ccounts[, doublet_ids[,2]]
doublet_pcs <- predict(pca,
                       newdata = sqrt( (t(doublet_raw) / colSums(doublet_raw))[, is_informative] ))

```

We again use RcppAnnoy to find nearest neighbors, this time also for the 
synthetic doublets on top of the cells:
```{r}
featureMatrix <- rbind(pca$x, doublet_pcs); k_nn <- 50
annoy <- new( AnnoyEuclidean, ncol(featureMatrix) )
for( i in 1:nrow(featureMatrix) ) 
  annoy$addItem( i-1, featureMatrix[i,] )
annoy$build( 50 ) # builds a forest  of n_trees trees. More trees gives higher precision when querying.
nn_doublets <- t( sapply( 1:annoy$getNItems(), function(i) annoy$getNNsByItem( i-1, k_nn) + 1 ) )
nndists_doublets <- sapply( 1:ncol(nn_doublets), function(j) sqrt( rowSums( ( featureMatrix - featureMatrix[ nn_doublets[,j], ] )^2 ) ) )
rm(featureMatrix, annoy)


# percentage of synthetic doublets in neighborhood for each cell:
dblts_perc <- rowMeans( nn_doublets > ncol(counts) )[ 1:ncol(counts) ]



# Run UMAP with Annoy's output
ump2 <- uwot::umap( NULL, nn_method = list( idx=nn_doublets, dist=nndists_doublets), 
                    n_threads=40, spread = 15, verbose=TRUE )

is_synth <- 1:nrow(ump2) > nrow(pca$x)
```



```{r, echo=FALSE}
tmp <- data.frame(umap_euc,
                  diagnosis = cellinfo$diagnosis,
                  clean = dblts_perc < 3/50  & nn_inothercluster < 1,
                  Gene = Tcounts[, "TTF2"] / sfs/mean(1/sfs),
                  cl = celltypes_louv)
ggplot() + coord_fixed()+
  geom_point(data=filter(tmp,  clean), aes(X1, X2, col = cl), size=.1) +
  geom_point(data=filter(tmp, !clean), aes(X1, X2), col = "black", size=.1) +
  geom_label(data=group_by(tmp, cl) %>% summarise(X1=mean(X1), X2=mean(X2)), aes(X1, X2, label=cl)) + ggtitle("Black dots show cells with doublets/wrong cluster amongst NN")

tmp <- as.matrix(table(sample=cellinfo$sample, clean = dblts_perc < 3/50  & nn_inothercluster < 1))
data.frame(sample = rownames(tmp), dirtyProportion = tmp[,1] / (tmp[,1] + tmp[,2])) %>% left_join(sampleTable, by="sample") %>% ggplot(aes(sample, dirtyProportion, col = diagnosis))+geom_point() + ylab("% of cells with doublets/wrong cluster amongst NN")

```






## Find celltypes with smoothing

```{r}
tricube_fromNN1 <- function(x, halfwidth=1) {
  # tricube kernel function with sef: self equals first neighbor.
  #
  # formula adapted from (wikipedia)[https://en.wikipedia.org/wiki/Kernel_(statistics)],
  # and expanded to contain `halfwidth`.
  # distance to oneself is 0 so we mask it:
  self_id <- which.min(x)
  x[self_id] <- NA
  nn_dist <- min(x, na.rm = TRUE) # distance to first nearest neighbor
  x <- x - nn_dist
  halfwidth <- halfwidth - nn_dist
  tricube <- 70/81/halfwidth * (1 - abs(x/halfwidth)^3)^3
  # outside of kernel support (-halfwidth, +halfwidth), tricube is defined as 0:
  tricube[ abs(x) > halfwidth ] <- 0
  tricube[self_id] <- tricube[which.max(tricube)]
  return(tricube)
}


kernel_weights <- apply(nndists_cells,
                        1,
                        function(d) tricube_fromNN1(d, max(d)))
```


```{r}
smooth_list <- lapply(rownames(Ccounts), function(g) NULL)
names(smooth_list) <- rownames(Ccounts) # 5 MB of empty shell, who cares


knn_smooth <- function(g = "SYT1"){
# knn-smooth a gene with tricube weights.
# Side effect: saves smoothing to smooth_list so we don't have to recompute.

if(is.null(smooth_list[[g]])){ 
   norm_umis <- matrix(Ccounts[g, c(nn_cells)] / sfs[c(nn_cells)],
                       ncol = ncol(nn_cells))
   knn_smoothed <- rowSums(norm_umis * t(kernel_weights)) / colSums(kernel_weights)
   smooth_list[[g]] <<- knn_smoothed
   }
  
  smooth_list[[g]]
}


make_p <- function(df) {  # custom function to save some typing - pure laziness
  ggplot(data=df, aes(X1, X2, col = Gene))+geom_point(size=.1)+coord_fixed() +
  scale_color_gradientn(colours = rev(rje::cubeHelix(100))[5:100], trans = "sqrt")
}
```



Smoothing looks convincing:
```{r}
plot_grid(
    data.frame(umap_euc, Gene = Tcounts[, "SYT1"]/sfs) %>% make_p,
    data.frame(umap_euc, Gene = knn_smooth("SYT1")) %>% make_p
)
```




### CUX2 cells


Cells can be separated in principle by smoothed cux2 expression.
DPP10 is anticorrelated with CUX2.
RORB is a marker used in the paper for L4.
```{r}
data.frame(umap_euc,
           syt1 = knn_smooth("SYT1"),
           cux2 = knn_smooth("CUX2"),
           rorb = knn_smooth("RORB")) %>% 
  ggplot() + geom_point(aes(syt1, cux2, col = cux2 > .00025), size=.1) + coord_fixed() + 
  scale_x_continuous(trans = "sqrt") +
  scale_y_continuous(trans = "sqrt")
```
Patient heterogeneity in CUX2:
```{r}
data.frame(cellinfo, cux2 = knn_smooth("CUX2"), celltypes_louv) %>%
  mutate(tmp = case_when(
    celltypes_louv %in% c("Neuron_excit", "neurons_NRGN") ~ as.character(celltypes_louv),
    TRUE ~ "other"
  ) ) %>% 
  filter(celltypes_louv == "Neuron_excit") %>%
  ggplot(aes(cux2, col = factor(individual)))+ facet_wrap(~region) + geom_density() +
  scale_x_continuous(trans=power_trans(1/2)) +
  theme(axis.text.x  =  element_text(angle = 90))
```



What correlates with cux2? 
```{r}
sel <- celltypes_louv == "Neuron_excit"   &   
  dblts_perc < 3/50  & nn_inothercluster < 1
poisson_vmr <- mean(1/sfs[sel])
gene_means <- rowMeans( norm_counts[, sel] )
gene_vars <- rowVars_spm( norm_counts[,sel] )
is_expressed <- colSums( Tcounts[sel,] != 0 ) > 200
is_informative <- gene_vars/gene_means > 1.5 * poisson_vmr  &  is_expressed
plot(gene_means, gene_vars/gene_means, pch=".", log = "xy")
points(gene_means[is_informative], (gene_vars/gene_means)[is_informative], pch=".", col = "red" )

# compute patient-ignorant (across all cells).
# Note:  correlation coefs are stronger after smoothing but order is similar - at least for CUX2
gene_cors <- cor(sqrt(knn_smooth("CUX2"))[sel],
                 sqrt(as.matrix(t(norm_counts[is_informative,sel]))))[1,]
gene_cors[ order(abs(gene_cors), decreasing = TRUE)[1:20] ]
```

```{r}
plot_grid(
  data.frame(umap_euc, Gene = Tcounts[, "CUX2"]/sfs) %>% make_p,
  data.frame(umap_euc, Gene = Tcounts[, "DPP10"]/sfs) %>% make_p
)
```

ASD vs control: do gene correlations with CUX2 change with disease?
```{r}
normcounts_for_cor <- sqrt(as.matrix(t(norm_counts[is_informative, ])))
cux2_for_cor <- sqrt(knn_smooth("CUX2")/sfs)
cors_per_sample <- lapply(unique(cellinfo$sample), function(smp){
  smp_sel <- cellinfo$sample == smp  &  sel
  print(paste0(smp, ":  ", sum(smp_sel)))
  drop(cor(cux2_for_cor[smp_sel], normcounts_for_cor[smp_sel,]))
}) %>% do.call(cbind, .)
colnames(cors_per_sample) <- unique(cellinfo$sample)

cors_factor <- data.frame(sample = colnames(cors_per_sample), stringsAsFactors = F) %>%
  left_join(sampleTable, by = "sample") %>% pull(diagnosis) %>% factor

library(genefilter)
res <- rowttests(cors_per_sample, cors_factor, tstatOnly = FALSE) 
res %>% rownames_to_column("Gene") %>% filter(p.value < .1) %>% arrange(desc(dm)) %>% head(n=20)
```


```{r}
data.frame(cors_factor,t(cors_per_sample)) %>% rownames_to_column("sample") %>%
    left_join(sampleTable, by = "sample") %>%
    ggplot(aes(cors_factor, LINGO2, col = region))+geom_jitter(height=0, width = .1)
```




### Excitatory Neurons, Oligodendrocytes, ...
Celltypes:
```{r}
plot_grid(
  p_louv + ggtitle("Louvain clusters"),
  p_paper+ ggtitle("Clusters from Velmeshev et al., Science 2019")
)
```


Excitatory Neurons
```{r}
SLC17A7 <- knn_smooth("SLC17A7") 
data.frame(umap_euc, Gene = Tcounts[, "SLC17A7"]/sfs) %>% make_p
data.frame(umap_euc, Gene = SLC17A7) %>% make_p
```



Oligodendrocytes
```{r}
PLP1 <- knn_smooth("PLP1")
data.frame(umap_euc, Gene = Tcounts[, "PLP1"]/sfs) %>% make_p
data.frame(umap_euc, Gene = PLP1) %>% make_p
```



Glial cells + endo according to paper, but I think it's astrocytes only
(in Science paper, microglia are marked nicely... could that be overplotting?!)
```{r}
SLC1A2 <- knn_smooth("SLC1A2")

data.frame(umap_euc, Gene = Tcounts[, "SLC1A2"]/sfs) %>% make_p
data.frame(umap_euc, Gene = SLC1A2/mean(1/sfs)) %>% make_p
```




Layer 2/3 (Margot and Simon)
```{r}
data.frame(umap_euc, Gene = Tcounts[, "CARM1P1"]/sfs) %>% make_p
```








## Gene-based classification


Smoothing is useful for gene-based questions, so let's ask some.



Here are excitatory neurons:
```{r}
is_cl  <- celltypes_louv == "Neuron_excit"   &   
  dblts_perc < 3/50  & nn_inothercluster < 1

```
and here are genes that looked bimodal in my linked charts app
(see commit 5a3e79ac7649b59606b897329ddea51624e3302e):
```{r hvgs_excitNeurons}
bimodal_genes <- c(
  "KIAA1217",
  "HTR2C",
  "ZNF385D",
  "TSHZ2",
  "HS3ST4",  # trimodal?
  "DLC1",
  "POU6F2",  # ill-separated peaks
  "CA10",  # ill-separated peaks
  "TMTC2",  # ill-separated peaks
  "CACNB2",  # ill-separated peaks
  "CTC-535M15.2",
  "Meis2",  # VMR is not spectacular but bimodality well visible
  "GRIN1",
  "CNTNAP5",
  "CPNE4"
  
)

not_bimodal <- c(
  "GPC5",
  "ENC1",
  "PTPRT",
  "SYN2",
  "STMN1",
  "INO80D",
  "MCTP1"  # trimodal, in my opinion
  
)
```


### HTR2C splits L5/6 cluster into two

```{r}
# execute once to compute smoothing
data.frame(cellinfo, Gene = knn_smooth("HTR2C")/mean(1/sfs)) %>% 
  ggplot(aes(tSNE1, tSNE2, col = Gene))+geom_point(size=.1)+coord_fixed()+scale_color_sqrt()
```

Compare this to the clusters from the paper: L5/6 clearly splits into two
parts, one expressing HTR2C and the other one not.
```{r}
cellinfo %>% ggplot(aes(tSNE1, tSNE2, col = cluster))+geom_point()
```

Let's select cells NOT expressing it:
```{r}
data.frame(cellinfo, Gene = knn_smooth("HTR2C")/mean(1/sfs) ) %>% 
  ggplot(aes(tSNE1, tSNE2, col = Gene < 1 & cluster == "L5/6"))+geom_point(size=.1)+coord_fixed()
```


```{r}
# run with or without HTR2C < 1, compare:
sel <- cellinfo$cluster == "L5/6"  #& knn_smooth("HTR2C")/mean(1/sfs) < 1

pseudobulks <- as.matrix(t( fac2sparse(cellinfo$sample[sel]) %*% t(Ccounts[, sel]) ))
coldat <- filter(sampleTable, sample %in% colnames(pseudobulks)) %>% 
  mutate(individual = factor(individual),
         diagnosis = factor(diagnosis, levels = c("Control", "ASD")),
         region    = factor(region))
rownames(coldat) <- coldat$sample

dds <- DESeq2::DESeqDataSetFromMatrix( pseudobulks,
                               coldat[colnames(pseudobulks), ],
                               design = ~ sex + region + age + diagnosis )
# For cluster 5, I tested that we do not need interactions between sex, region and diagnosis. I used
# DESeq's LTR for this (see mail to Simon at mid-September 2019).
dds <- DESeq2::DESeq(dds, 
             parallel=TRUE, BPPARAM=BiocParallel::MulticoreParam(20))
res_df <- DESeq2::results(dds, name = "diagnosis_ASD_vs_Control") %>% as.data.frame() %>% rownames_to_column("Gene")
```


```{r}
plot(-log10(res_null$padj), -log10(res_alt$padj), asp=1, pch=20, cex=.5); abline(0,1); abline(h=1); abline(v=1)
```














### TSHZ2 splits L4 into two
The L4 cluster from the paper (marked by RORB) splits into two "halves" - one
expressing TSHZ2, COBLL1, VWC2L and others, while the other
half is negative for those and expresses GRID2, COL24A1, TENM3 and CA10.


In PFC the effect seems larger than in ACC:
```{r}
g <- "TSHZ2"

plot_grid(
 data.frame(umap_euc, Gene = Tcounts[, g]/sfs/mean(1/sfs)) %>% make_p,
 data.frame(umap_euc, Gene = knn_smooth(g)/mean(1/sfs)) %>% make_p 
)

# in paper TSNE:
plot_grid(
  data.frame(cellinfo, Gene = knn_smooth("TSHZ2")/mean(1/sfs)) %>%
    ggplot(aes(tSNE1, tSNE2, col = Gene))+geom_point(size=.1) + coord_fixed()+
    scale_color_sqrt() + facet_wrap(~ region + diagnosis),
  cellinfo %>% ggplot(aes(tSNE1, tSNE2, col = cluster))+ geom_point(size=.1)+ 
    coord_fixed() +facet_wrap(~region + diagnosis) + theme(legend.position = "none"),
  ncol=2
 )
```


TSHZ2 is bimodal in PFC region and marks cells across cluster boundaries.
```{r}

# classification cut-off:     q/sfs/mean(1/sfs)  > 1.2
data.frame(cellinfo, Gene = knn_smooth(g)/mean(1/sfs), celltypes_louv) %>%
    filter(celltypes_louv == "Neuron_excit", region == "PFC") %>%
    ggplot(aes(Gene, fill = factor(diagnosis)))+geom_histogram(bins=50) +
    scale_x_continuous(trans=power_trans(1/2), labels = semi_scientific_formatting) +
    theme(axis.text.x  =  element_text(angle = 90)) + facet_wrap(~individual, scales = "free_y") + ggtitle("PFC only") + geom_vline(xintercept = 1.2)

```


#### Genes discriminating TSHZ2-positive and negative excitatory Neurons:
I simply find markers for the two "halves" of the L4 cluster from the paper using
DESeq. This chunk is a bit messy, feel free to skip.
```{r}
cell_groups <- paste(
  paste0(cellinfo$region, "_", cellinfo$individual),
  ifelse(knn_smooth("TSHZ2")/mean(1/sfs) > 1.2, "positive", "negative"),
  sep="_")


sel <- celltypes_louv == "Neuron_excit"  & dblts_perc < 3/50  & nn_inothercluster < 1
pseudobulks <- as.matrix(t( fac2sparse(cell_groups[sel]) %*% t(Ccounts[, sel]) ))

coldat <- data.frame(do.call(rbind, colnames(pseudobulks) %>% str_split("_")))
colnames(coldat) <- c("region", "individual", "MarkerExpression")
rownames(coldat) <- colnames(pseudobulks)


library(DESeq2)
dds <- DESeqDataSetFromMatrix(pseudobulks[, grepl("^PFC_", colnames(pseudobulks))],
                              coldat[grepl("^PFC_", colnames(pseudobulks)), ],
                              design = ~ individual + MarkerExpression)
dds <- DESeq(dds)
results(dds, name = "MarkerExpression_positive_vs_negative") %>% as.data.frame() %>%
  rownames_to_column("Gene") %>%
  filter(padj < .1, baseMean > 50) %>% arrange(desc(abs(log2FoldChange))) %>%
  filter(!grepl("^RP", Gene)) %>% head(n=20) %>% pull(Gene)



"HTR2C", "TSHZ2"      "COBLL1"     "IFNG-AS1"   "LINC00507"  "VWC2L"      "GABRG1"     "CBLN2" 
"NXPH2"     
"AC133680.1" "NPSR1-AS1"  "GRID2"      "GOLIM4"     "COL24A1"    "GULP1"      "SLC38A11"   "TENM3"
"ZNF804A"   
"SERPINE2"   "GNG2"



g <- "TSHZ2"
g <- "COBLL1"
cellinfo %>%
  left_join(data.frame(cell = rownames(Tcounts), Gene = Tcounts[, "TSHZ2"]/sfs/mean(1/sfs))) %>%
    ggplot(aes(tSNE1, tSNE2, col = Gene)) + geom_point(size = .1) + scale_color_sqrt() + 
    ggtitle(g) + coord_fixed() + facet_wrap(~ diagnosis + region)




```




#### DEGs for L4 and TSHZ2+ L4 - how different are they?
Number of cells per pseudobulk:
```{r}
table(sample = cellinfo$sample,
      L4 = cellinfo$cluster == "L4" & knn_smooth("TSHZ2")/mean(1/sfs) > 1.2 &
           cellinfo$region == "PFC")
```



TSHZ2-bimodality is less pronounced in region ACC judged from the histograms (not shown),
but note that's probably because
it has less cells per donor in L4.

If we limit to cells from region PFC and demand padj < .1, we get 0 DEGs for
L4 and 10 DEGs for L4/expressing TSHZ2. (FYI: This is without excluding potential doublets).
This could make sense if TSHZ2-expressing cells are different from non-expressing
cells, so if we take ALL of L4 we throw together different cell types in each sample,
and I expect this to increase pseudobulk variability.

Two notes of caution, however:
  - the p-value histogram looks strange (uniform from 0-.6, then a peak),
perhaps pseudobulks do NOT follow negative binomial?
  - Also, if we include both regions, we get more significant hits overall, somewhat
non-surprising. However, now we get MUCH more hits for the entire L4 cluster
as when we only include TSHZ2-expressing cells from L4, so it's the other way
around than before... this makes no sense to me, it is difficult to draw a
conclusion.

```{r}
sel <-  cellinfo$cluster == "L4"  &     cellinfo$region == "PFC" |
        cellinfo$cluster == "L4" & cellinfo$region == "ACC"
# sel <- sample(which(cellinfo$cluster == "L4"), sum(sel))   # for comparison


pseudobulks <- as.matrix(t( fac2sparse(cellinfo$sample[sel]) %*% t(Ccounts[, sel]) ))
coldat <- filter(sampleTable, sample %in% colnames(pseudobulks)) %>% 
  mutate(individual = factor(individual),
         diagnosis = factor(diagnosis, levels = c("Control", "ASD")),
         region    = factor(region))
rownames(coldat) <- coldat$sample


dds <- DESeq2::DESeqDataSetFromMatrix( pseudobulks,
                               coldat[colnames(pseudobulks), ],
                               design = ~ sex +  age + region + diagnosis )
# For cluster 5, I tested that we do not need interactions between sex, region and diagnosis. I used
# DESeq's LTR for this (see mail to Simon at mid-September 2019).
dds <- DESeq2::DESeq(dds, 
             parallel=TRUE, BPPARAM=BiocParallel::MulticoreParam(20))
res_df <- DESeq2::results(dds, name = "diagnosis_ASD_vs_Control") %>% as.data.frame() %>% rownames_to_column("Gene")

```

This is one of the 10 hits we get when excluding TSHZ2-negative cells from L4:
```{r}
data.frame(cellinfo, Gene = Tcounts[, "LSM10"], sfs,
           sel = cellinfo$cluster == "L4" &
             knn_smooth("TSHZ2")/mean(1/sfs) < 1.2 &
             cellinfo$region == "PFC") %>% 
  filter(sel) %>% 
  ggplot(aes(tSNE1, tSNE2, col = Gene/sfs/mean(1/sfs)))+
  geom_point(size=.1)+ scale_color_sqrt() +
  facet_wrap(~diagnosis) + coord_fixed()
```













## Compare Autism versus Control


```{r}
sel <- cellinfo$cluster == "L5/6"  & knn_smooth("HTR2C")/mean(1/sfs) < 1
#& dblts_perc < 3/50  & nn_inothercluster < 1
pseudobulks <- as.matrix(t( fac2sparse(cellinfo$sample[sel]) %*% t(Ccounts[, sel]) ))
coldat <- filter(sampleTable, sample %in% colnames(pseudobulks)) %>% 
  mutate(individual = factor(individual),
         diagnosis = factor(diagnosis, levels = c("Control", "ASD")),
         region    = factor(region))
rownames(coldat) <- coldat$sample

dds <- DESeq2::DESeqDataSetFromMatrix( pseudobulks,
                               coldat[colnames(pseudobulks), ],
                               design = ~ sex + region + age + diagnosis )
# For cluster 5, I tested that we do not need interactions between sex, region and diagnosis. I used
# DESeq's LTR for this (see mail to Simon at mid-September 2019).
dds <- DESeq2::DESeq(dds, 
             parallel=TRUE, BPPARAM=BiocParallel::MulticoreParam(20))
res_df <- DESeq2::results(dds, name = "diagnosis_ASD_vs_Control") %>% as.data.frame() %>% rownames_to_column("Gene")
```



```{r}




# new thought: we have to compare same number of cells, so we kick out
# either n doublets or n random cells and see where signal is better

plot(-log10(res_excit_random$padj), -log10(res_excit_rmD$padj), asp=1); abline(0,1); abline(h=1); abline(v=1)


plot(-log10(res_SST_random$padj), -log10(res_SST_rmD$padj), asp=1); abline(0,1); abline(h=1); abline(v=1)


plot(-log10(res_VIP_random$padj), -log10(res_VIP_rmD$padj), asp=1); abline(0,1); abline(h=1); abline(v=1)

plot(-log10(res_l56$padj), -log10(res_l56_noHTR2C$padj), asp=1); abline(0,1); abline(h=1); abline(v=1)
```




```{r}


data.frame(umap_euc, Gene = Tcounts[, "ZNF770"], sfs=sfs, diagnosis=cellinfo$diagnosis) %>%
  ggplot(aes(X1, X2, col=Gene/sfs/mean(1/sfs)))+geom_point(size=.1) +
  scale_color_sqrt(name="ZNF770") +
  facet_wrap(~ diagnosis) + coord_fixed()


data.frame(cellinfo, Gene = Tcounts[, "ZNF385D"], sfs=sfs) %>% 
    ggplot(aes(tSNE1, tSNE2, col = Gene/sfs/mean(1/sfs)))+geom_point(size=.1) + coord_fixed() + scale_color_sqrt()



```








## savepoint

```{r}
# save(pca,
#      file = file.path(path, "savepoint", "pca_40pcs_scaling_2311genes.RData"))
# save(umap_euc,
#      file = file.path(path, "savepoint", "umap_euc_spread10.RData"))
# 
# 
# save(list = c("cl_louvain", "celltypes_louv", "nn_cells", "nndists_cells",
#               "nn_inothercluster"),
#      file = file.path(path, "savepoint", "clusters.RData"))
# 
# save(list = c("nn_doublets", "nndists_doublets", "cellsA", "cellsB",
#                 "dblts_perc", "is_synth", "ump2"),
#      file = file.path(path, "savepoint", "doublets.RData"))


load(file.path(path, "savepoint", "pca_40pcs_scaling_2311genes.RData"))
load(file.path(path, "savepoint", "umap_euc_spread10.RData"))
load(file.path(path, "savepoint", "clusters.RData"))
load(file.path(path, "savepoint", "doublets.RData"))
```

















# scpr

Let's see how long scpr smoothing takes on such large data.

```{r}
tricube_fromNN1 <- function(x, halfwidth=1) {
  # tricube kernel function with sef: self equals first neighbor.
  #
  # formula adapted from (wikipedia)[https://en.wikipedia.org/wiki/Kernel_(statistics)],
  # and expanded to contain `halfwidth`.
  # distance to oneself is 0 so we mask it:
  self_id <- which.min(x)
  x[self_id] <- NA
  nn_dist <- min(x, na.rm = TRUE) # distance to first nearest neighbor
  x <- x - nn_dist
  halfwidth <- halfwidth - nn_dist
  tricube <- 70/81/halfwidth * (1 - abs(x/halfwidth)^3)^3
  # outside of kernel support (-halfwidth, +halfwidth), tricube is defined as 0:
  tricube[ abs(x) > halfwidth ] <- 0
  tricube[self_id] <- tricube[which.max(tricube)]
  return(tricube)
}
```




```{r}
# same for every gene:
totalUMI <- sfs
lambda <- 1
lambda_seq <- 10^(seq( log10(lambda), log10(1000), length.out = 100))
kernel_weights <- apply(nndists_cells, 1, function(d) tricube_fromNN1(d, max(d)))



g <- "CUX2"
gene_umis <- Tcounts[, g]
scaled_pcs <- scale(pca$x)


```


smooth one cell:
```{r}
fitcell <- function(cell_id) {
  neighbors <- nn_cells[cell_id, ]
  if(sum(gene_umis[neighbors]) <= 5){return(0)} # glmnet throws error otherwise
  fit <- glmnet::glmnet(
    x = scaled_pcs[neighbors,],
    y = gene_umis[neighbors],
    weights = kernel_weights[, cell_id],
    family = "poisson",
    offset = log( totalUMI[neighbors] ),
    lambda = lambda_seq,
    alpha = 0, # ridge regression
    standardize = FALSE # featureMatrix was scaled already above
    )
  # glmnet.predict returns the linear predictor irrespective of whether
  # type is set to "link" or "response", so we exponentiate it to obtain mu:
  estimate <- exp( glmnet::predict.glmnet(
    # What I mean by 'linear predictor' and 'mu':
    # In the following Poisson-GLM form, the RHS (right-hand side) is the
    # linear predictor and mu is the estimated Poisson rate (smoothed UMI):
    #     log( mu ) = log(totalUMI) + X %*% Beta
    object    = fit,
    newx      = matrix(scaled_pcs[cell_id,], nrow=1),
    s         = lambda,
    newoffset = log(totalUMI[cell_id]),
    type      = "link") )

  estimate
}
```



```{r}
date()
res <- lapply(1:length(gene_umis), fitcell) # 4 minutes 20 sec
date()
```














